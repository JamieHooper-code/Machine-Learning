{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13134a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "221/221 - 2s - loss: 0.0138 - 2s/epoch - 9ms/step\n",
      "Epoch 2/10\n",
      "221/221 - 0s - loss: 0.0075 - 373ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "221/221 - 0s - loss: 0.0064 - 364ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "221/221 - 0s - loss: 0.0062 - 372ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "221/221 - 0s - loss: 0.0057 - 353ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "221/221 - 0s - loss: 0.0058 - 373ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "221/221 - 0s - loss: 0.0055 - 372ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "221/221 - 0s - loss: 0.0058 - 363ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "221/221 - 0s - loss: 0.0054 - 356ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "221/221 - 0s - loss: 0.0054 - 354ms/epoch - 2ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Train Score: 1524.57 RMSE\n",
      "Test Score: 2022.07 RMSE\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (109,1) into shape (99,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 91\u001b[0m\n\u001b[0;32m     88\u001b[0m test_end_index \u001b[38;5;241m=\u001b[39m test_start_index \u001b[38;5;241m+\u001b[39m test_size\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Ensure the test predictions fit within the testPredictPlot array\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m \u001b[43mtestPredictPlot\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_start_index\u001b[49m\u001b[43m:\u001b[49m\u001b[43mtest_end_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m testPredict\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Plot baseline and predictions\u001b[39;00m\n\u001b[0;32m     94\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (109,1) into shape (99,1)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess data\n",
    "dataframe_names = ['master_data_setV0.csv']  # Add your CSV file names here\n",
    "\n",
    "for file_name in dataframe_names:\n",
    "    df = pd.read_csv(file_name)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.set_index('Date', inplace=True)\n",
    "    df = df[df['State'] == 'Texas']  # Filtering by state\n",
    "    df = df.drop(columns=['State', 'Division'])  # Dropping unnecessary columns\n",
    "\n",
    "    # Assuming 'Value' is the target variable\n",
    "    y = df['Value'].values.reshape(-1, 1)\n",
    "\n",
    "    # Scale the data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    y_scaled = scaler.fit_transform(y)\n",
    "\n",
    "    # Function to create a dataset for LSTM\n",
    "    def create_dataset(data, look_back=1):\n",
    "        X, Y = [], []\n",
    "        for i in range(len(data) - look_back - 1):\n",
    "            a = data[i:(i + look_back), 0]\n",
    "            X.append(a)\n",
    "            Y.append(data[i + look_back, 0])\n",
    "        return np.array(X), np.array(Y)\n",
    "\n",
    "    look_back = 12\n",
    "    X, Y = create_dataset(y_scaled, look_back)\n",
    "\n",
    "    # Split into train and test sets\n",
    "    train_size = int(len(X) * 0.67)\n",
    "    test_size = len(X) - train_size\n",
    "    trainX, trainY = X[:train_size], Y[:train_size]\n",
    "    testX, testY = X[train_size:], Y[train_size:]\n",
    "\n",
    "    # Reshape input to be [samples, time steps, features]\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(1, look_back)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(trainX, trainY, epochs=10, batch_size=1, verbose=2)\n",
    "\n",
    "    # Make predictions\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "\n",
    "    # Invert predictions\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform([trainY])\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform([testY])\n",
    "\n",
    "    # Calculate RMSE\n",
    "    trainScore = np.sqrt(mean_squared_error(trainY[0], trainPredict[:, 0]))\n",
    "    print(f'Train Score: {trainScore:.2f} RMSE')\n",
    "    testScore = np.sqrt(mean_squared_error(testY[0], testPredict[:, 0]))\n",
    "    print(f'Test Score: {testScore:.2f} RMSE')\n",
    "\n",
    "    # Calculate the number of data points used in training and testing\n",
    "    train_size = len(trainX)\n",
    "    test_size = len(testX)\n",
    "\n",
    "    # Initialize the plotting arrays\n",
    "    trainPredictPlot = np.empty_like(y_scaled)\n",
    "    trainPredictPlot[:, :] = np.nan\n",
    "    testPredictPlot = np.empty_like(y_scaled)\n",
    "    testPredictPlot[:, :] = np.nan\n",
    "\n",
    "    # Insert the training predictions\n",
    "    trainPredictPlot[look_back:train_size + look_back, :] = trainPredict\n",
    "\n",
    "    # Calculate the start and end indices for the test predictions in the plot\n",
    "#     test_start_index = train_size + (look_back * 2) - 1\n",
    "    test_start_index = train_size + (look_back) - 1\n",
    "    test_end_index = test_start_index + test_size\n",
    "\n",
    "    # Ensure the test predictions fit within the testPredictPlot array\n",
    "    testPredictPlot[test_start_index:test_end_index, :] = testPredict\n",
    "\n",
    "    # Plot baseline and predictions\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(scaler.inverse_transform(y_scaled), label='Original Data')\n",
    "    plt.plot(trainPredictPlot, label='Train Prediction')\n",
    "    plt.plot(testPredictPlot, label='Test Prediction')\n",
    "    plt.title(f'Forecast with LSTM for {file_name}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Forecasting out to 2030\n",
    "    last_date = df.index[-1]\n",
    "    months_to_predict = (2030 - last_date.year) * 12 - last_date.month\n",
    "\n",
    "    # Start with the last `look_back` months from the original dataset\n",
    "    input_seq = y_scaled[-look_back:]\n",
    "\n",
    "    # Store the forecasts\n",
    "    forecasts = []\n",
    "\n",
    "    # Iteratively predict each future month\n",
    "    for _ in range(months_to_predict):\n",
    "        # Reshape input_seq to the format required by the LSTM model\n",
    "        lstm_input = np.reshape(input_seq, (1, 1, look_back))\n",
    "\n",
    "        # Predict the next step\n",
    "        predicted_step = model.predict(lstm_input)\n",
    "\n",
    "        # Append the prediction to forecasts\n",
    "        forecasts.append(predicted_step[0, 0])\n",
    "\n",
    "        # Update the input sequence for the next prediction\n",
    "        input_seq = np.append(input_seq[1:], predicted_step)\n",
    "\n",
    "    # Transform forecasts back to the original scale\n",
    "    forecasts = scaler.inverse_transform(np.array(forecasts).reshape(-1, 1))\n",
    "\n",
    "    # Create a time series for the forecasts\n",
    "    forecast_dates = pd.date_range(start=last_date + pd.DateOffset(months=1), periods=months_to_predict, freq='M')\n",
    "    forecast_series = pd.Series(data=forecasts.ravel(), index=forecast_dates)\n",
    "\n",
    "    # Plot baseline, predictions, and future forecasts\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(df.index, y, label='Original Data')\n",
    "    plt.plot(forecast_series.index, forecast_series.values, label='Forecast to 2030', color='red')\n",
    "    plt.title(f'Forecast with LSTM up to 2030 for {file_name}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb37c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2249710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorEnv",
   "language": "python",
   "name": "tensorenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
